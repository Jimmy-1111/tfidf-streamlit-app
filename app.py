import streamlit as st
import pandas as pd
import io
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from janome.tokenizer import Tokenizer
from zipfile import ZipFile

janome_tokenizer = Tokenizer()

# âœ… åƒ…ä¿ç•™èªæ„ä¸Šæœ‰åƒ¹å€¼çš„è©ï¼šåè©ã€å‹•è©ã€å½¢å®¹è©
def tokenize_japanese(text):
    tokens = []
    for token in janome_tokenizer.tokenize(text):
        part = token.part_of_speech.split(',')[0]
        if part in ['åè©', 'å‹•è©', 'å½¢å®¹è©']:
            tokens.append(token.surface)
    return tokens

def extract_date_from_filename(filename):
    match = re.match(r'^([0-9]{4}(Q[1-4])?)', filename)
    return match.group(1) if match else "æœªçŸ¥"

def compute_tfidf(sentences):
    vectorizer = TfidfVectorizer(tokenizer=tokenize_japanese)
    tfidf_matrix = vectorizer.fit_transform(sentences)
    return vectorizer, tfidf_matrix

def extract_keywords(tfidf_matrix, vectorizer, top_n=5):
    feature_names = vectorizer.get_feature_names_out()
    keywords = []
    for i in range(tfidf_matrix.shape[0]):
        row = tfidf_matrix[i].toarray().flatten()
        top_indices = row.argsort()[::-1]
        selected = [feature_names[idx] for idx in top_indices if row[idx] > 0][:top_n]
        keywords.append("ã€".join(selected) if selected else "ï¼ˆç„¡ï¼‰")
    return keywords

def build_tfidf_summary(tfidf_matrix, vectorizer):
    feature_names = vectorizer.get_feature_names_out()
    tfidf_array = tfidf_matrix.toarray()
    tf_sum = np.sum(tfidf_array, axis=0)
    tf_avg = np.mean(tfidf_array, axis=0)
    tf_count = np.count_nonzero(tfidf_array, axis=0)
    summary_df = pd.DataFrame({
        "è©å½™ï¼ˆé—œéµå­—ï¼‰": feature_names,
        "TF-IDFï¼ˆç¸½å’Œï¼‰": tf_sum,
        "TF-IDFï¼ˆå¹³å‡ï¼‰": tf_avg,
        "å‡ºç¾æ¬¡æ•¸": tf_count
    }).sort_values(by="TF-IDFï¼ˆç¸½å’Œï¼‰", ascending=False)
    return summary_df

# Streamlit app
st.title("ğŸ“Š TF-IDF é—œéµè©åˆ†æå·¥å…·ï¼ˆæ’é™¤èªåŠ©è©èˆ‡æ¨™é»ï¼‰")
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ Excel æª”æ¡ˆï¼ˆå¯å¤šé¸ï¼‰", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    column_name = st.text_input("è«‹è¼¸å…¥è¦åˆ†æçš„æ¬„ä½åç¨±ï¼ˆé è¨­ç‚ºï¼šèªå¥å…§å®¹ï¼‰", value="èªå¥å…§å®¹")

    if st.button("é–‹å§‹åˆ†æ"):
        with st.spinner("åˆ†æä¸­..."):

            combined_df = pd.DataFrame()
            output_files = []
            all_dates = []
            all_sentences = []

            for file in uploaded_files:
                filename = file.name
                date_tag = extract_date_from_filename(filename)
                all_dates.append(date_tag)

                df = pd.read_excel(file)
                if column_name not in df.columns:
                    st.warning(f"{filename} ç¼ºå°‘æ¬„ä½ï¼š{column_name}ï¼Œå·²ç•¥é")
                    continue

                df = df.dropna(subset=[column_name])
                sentences = df[column_name].astype(str).tolist()
                if not sentences:
                    st.warning(f"{filename} ç„¡æœ‰æ•ˆèªå¥ï¼Œå·²ç•¥é")
                    continue

                vectorizer, tfidf_matrix = compute_tfidf(sentences)
                keywords = extract_keywords(tfidf_matrix, vectorizer)

                df["é—œéµè©(TFIDF)"] = keywords
                df.insert(0, "è³‡æ–™æ—¥æœŸ", date_tag)

                buffer = io.BytesIO()
                df.to_excel(buffer, index=False)
                output_files.append((f"{filename[:-5]}_tfidf.xlsx", buffer))

                df["_ä¾†æºæª”å"] = filename
                combined_df = pd.concat([combined_df, df], ignore_index=True)
                all_sentences.extend(sentences)

            if not all_sentences:
                st.error("ç„¡æœ‰æ•ˆèªå¥å¯åˆ†æ")
                st.stop()

            vectorizer, tfidf_matrix = compute_tfidf(all_sentences)
            keywords = extract_keywords(tfidf_matrix, vectorizer)
            combined_df["é—œéµè©(TFIDF)"] = keywords
            tfidf_summary_df = build_tfidf_summary(tfidf_matrix, vectorizer)

            try:
                sorted_dates = sorted([int(d[:4]) for d in all_dates if d[:4].isdigit()])
                min_date, max_date = str(sorted_dates[0]), str(sorted_dates[-1])
            except:
                sorted_dates = sorted(all_dates)
                min_date, max_date = sorted_dates[0], sorted_dates[-1]

            merged_filename = f"tfidf_ç¸½è¡¨åˆä½µ_{min_date}-{max_date}.xlsx"
            merged_buffer = io.BytesIO()
            with pd.ExcelWriter(merged_buffer, engine="openpyxl") as writer:
                combined_df.to_excel(writer, sheet_name="åˆä½µå¥å­åˆ†æ", index=False)
                tfidf_summary_df.to_excel(writer, sheet_name="TFIDFé—œéµå­—ç¸½è¡¨", index=False)
            merged_buffer.seek(0)
            output_files.append((merged_filename, merged_buffer))

            zip_buffer = io.BytesIO()
            with ZipFile(zip_buffer, "w") as zipf:
                for fname, buffer in output_files:
                    buffer.seek(0)
                    zipf.writestr(fname, buffer.read())
            zip_buffer.seek(0)

        st.success("åˆ†æå®Œæˆ âœ…")
        st.download_button("ğŸ“¥ ä¸‹è¼‰åˆ†æçµæœï¼ˆZIP å£“ç¸®åŒ…ï¼‰", zip_buffer, file_name="tfidf_outputs.zip")
